---
# Token-based Rate Limiting EnvoyFilter
# This filter counts tokens in LLM responses and enforces per-minute token limits
apiVersion: networking.istio.io/v1alpha3
kind: EnvoyFilter
metadata:
  name: token-rate-limit-filter
  namespace: istio-system
spec:
  workloadSelector:
    labels:
      gateway.networking.k8s.io/gateway-name: inference-gateway  # Target the inference gateway
  configPatches:
  # Add Lua script for token counting
  - applyTo: HTTP_FILTER
    match:
      context: GATEWAY
      listener:
        filterChain:
          filter:
            name: "envoy.filters.network.http_connection_manager"
            subFilter:
              name: "envoy.filters.http.router"
    patch:
      operation: INSERT_BEFORE
      value:
        name: envoy.filters.http.lua
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.http.lua.v3.Lua
          inline_code: |
            -- Token counting and rate limiting logic
            function envoy_on_request(request_handle)
              -- Get user identity from auth headers (set by Kuadrant/Authorino)
              local auth_header = request_handle:headers():get("authorization")
              
              if auth_header == nil then
                return
              end
              
              -- Extract API key from "APIKEY xxx" format
              local api_key = string.match(auth_header, "APIKEY%s+(%S+)")
              if api_key == nil then
                return
              end
              
              -- Define token limits per minute based on user tier
              -- Map API keys to tiers (this should match your secrets)
              local user_tiers = {
                ["freeuser1_key"] = "free",
                ["freeuser2_key"] = "free",
                ["premiumuser1_key"] = "premium",
                ["premiumuser2_key"] = "premium",
                ["enterpriseuser1_key"] = "enterprise"
              }
              
              local token_limits = {
                free = 200,      -- 200 tokens per minute
                premium = 1000,  -- 1000 tokens per minute
                enterprise = 5000 -- 5000 tokens per minute
              }
              
              -- Get user's tier
              local user_tier = user_tiers[api_key] or "free"  -- default to free
              
              -- Store user info for response processing
              request_handle:headers():add("x-user-key", api_key)
              request_handle:headers():add("x-user-tier", user_tier)
              request_handle:headers():add("x-token-limit", tostring(token_limits[user_tier]))
              
              -- Check current token usage from shared data
              local key = "tokens:" .. api_key
              local current_minute = os.date("%Y%m%d%H%M")
              local usage_key = key .. ":" .. current_minute
              
              local current_usage = request_handle:sharedData():get(usage_key)
              if current_usage == nil then
                current_usage = 0
              else
                current_usage = tonumber(current_usage)
              end
              
              -- Log for debugging
              request_handle:logInfo("Token rate limit check: user=" .. api_key .. " tier=" .. user_tier .. " usage=" .. current_usage .. "/" .. token_limits[user_tier])
              
              -- Check if user has exceeded limit
              if current_usage >= token_limits[user_tier] then
                request_handle:respond(
                  {[":status"] = "429"},
                  '{"error": "Token rate limit exceeded", "limit": ' .. token_limits[user_tier] .. 
                  ', "used": ' .. current_usage .. ', "reset_in_seconds": ' .. (60 - os.date("%S")) .. '}'
                )
              end
            end
            
            function envoy_on_response(response_handle)
              -- Extract token count from response
              local body = response_handle:body()
              if body == nil then
                return
              end
              
              local body_str = body:getBytes(0, body:length())
              local api_key = response_handle:headers():get("x-user-key")
              local user_tier = response_handle:headers():get("x-user-tier")
              local token_limit = response_handle:headers():get("x-token-limit")
              
              if api_key == nil or user_tier == nil then
                return
              end
              
              -- Parse response to get token usage
              -- vLLM returns usage in format: "usage":{"prompt_tokens":X,"completion_tokens":Y,"total_tokens":Z}
              local total_tokens = 0
              local usage_pattern = '"usage":%s*{[^}]*"total_tokens":%s*(%d+)'
              local tokens = string.match(body_str, usage_pattern)
              
              if tokens ~= nil then
                total_tokens = tonumber(tokens)
              else
                -- Fallback: estimate tokens (roughly 4 chars per token)
                -- Only for responses that look like completions
                if string.find(body_str, '"choices"') then
                  local content_pattern = '"content":%s*"([^"]*)"'
                  local content = string.match(body_str, content_pattern)
                  if content ~= nil then
                    total_tokens = math.ceil(string.len(content) / 4)
                  end
                end
              end
              
              -- Update token usage
              local key = "tokens:" .. api_key
              local current_minute = os.date("%Y%m%d%H%M")
              local usage_key = key .. ":" .. current_minute
              
              local current_usage = response_handle:sharedData():get(usage_key)
              if current_usage == nil then
                current_usage = 0
              else
                current_usage = tonumber(current_usage)
              end
              
              current_usage = current_usage + total_tokens
              response_handle:sharedData():set(usage_key, tostring(current_usage), 60) -- TTL 60 seconds
              
              -- Add headers with token information
              response_handle:headers():add("x-ratelimit-limit-tokens", token_limit)
              response_handle:headers():add("x-ratelimit-consumed-tokens", tostring(total_tokens))
              response_handle:headers():add("x-ratelimit-remaining-tokens", tostring(tonumber(token_limit) - current_usage))
              
              -- Clean up internal headers
              response_handle:headers():remove("x-user-key")
              response_handle:headers():remove("x-user-tier")
              response_handle:headers():remove("x-token-limit")
              
              -- Log for debugging
              response_handle:logInfo("Token usage recorded: user=" .. api_key .. " tokens=" .. total_tokens .. " total=" .. current_usage)
            end
---
# ConfigMap for token limits configuration (optional, for easy updates)
apiVersion: v1
kind: ConfigMap
metadata:
  name: token-rate-limits
  namespace: istio-system
data:
  limits.yaml: |
    # Token limits per tier
    tiers:
      free:
        tokens_per_minute: 200
        tokens_per_hour: 5000
        tokens_per_day: 50000
      premium:
        tokens_per_minute: 1000
        tokens_per_hour: 30000
        tokens_per_day: 500000
      enterprise:
        tokens_per_minute: 5000
        tokens_per_hour: 150000
        tokens_per_day: 2000000
    
    # Model-specific multipliers (for future use)
    model_multipliers:
      "simulator-model": 1.0
      "qwen3-0-6b-instruct": 1.0
      "llama-3-8b": 1.5
      "mixtral-8x7b": 2.0 